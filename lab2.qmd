---
title: "laboratorio 2"
code-fold: false
---

# Import libraries 

```{python}
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import OneHotEncoder

from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')

```
# Cargar dataset
```{python}
url = "https://raw.githubusercontent.com/erickedu85/dataset/refs/heads/master/tweets/tweets_totales_con_sentimiento_ml.csv"
df = pd.read_csv(url)
print(df.shape)
df.head()
```
# Limpieza
```{python}
# Eliminamos columnas que no aportan valor predictivo (identificadores, URLs, fechas, im谩genes, etc.)
cols_utiles = [
    'content', 'authorVerified', 'authorFollowers',
    'hashtags_count', 'mentions_count', 'content_length',
    'account_age_days'
]

df = df[cols_utiles].dropna()
print("Dimensiones despu茅s de limpieza:", df.shape)

# Limpieza de texto
def clean_text(text):
    text = re.sub(r"http\S+", "", text)       # eliminar URLs
    text = re.sub(r"@\w+", "", text)          # eliminar menciones
    text = re.sub(r"#\w+", "", text)          # eliminar hashtags
    text = re.sub(r"[^A-Za-z-每\s]", "", text) # eliminar s铆mbolos
    text = text.lower().strip()
    return text

df['content_clean'] = df['content'].apply(clean_text)

df.head()
```
Elimine variables que no aportan informaci贸n anal铆tica (IDs, fechas, etc.).

Elimine gran parte del ruido como "@,#,links", manteniendo solo palabras que pueden aportar valor sem谩ntico.

# Selecci贸n del target
```{python}
df['tipo_usuario'] = np.where(
    (df['authorFollowers'] > 1000) | (df['authorVerified'] == True),
    'Influencer',
    'Regular'
)
```
Primero verifico el tipo de usuario, como influencer o regular sgun el numero de seguidores que tiene

```{python}
# Creamos un puntaje ponderado de interacci贸n
df['interaccion_score'] = (
    df['mentions_count']*0.4 +
    df['hashtags_count']*0.3 +
    df['content_length']*0.2 +
    np.log1p(df['authorFollowers'])*0.1
)

# Definimos nivel alto o bajo seg煤n percentil 75
umbral = df['interaccion_score'].quantile(0.75)
df['nivel_interaccion'] = np.where(df['interaccion_score'] >= umbral, 'Alta', 'Baja')
```

Obtengo un porcentaje del tipo de interacciones que suele tener el usuario, esto para saber un aproximado de cuanta actividad constante suele tener

```{python}
def crear_perfil(row):
    if row['tipo_usuario'] == 'Influencer' and row['nivel_interaccion'] == 'Alta':
        return 'Influyente Activo'
    elif row['tipo_usuario'] == 'Influencer' and row['nivel_interaccion'] == 'Baja':
        return 'Influyente Pasivo'
    elif row['tipo_usuario'] == 'Regular' and row['nivel_interaccion'] == 'Alta':
        return 'Usuario Participativo'
    else:
        return 'Usuario Pasivo'

df['perfil_usuario'] = df.apply(crear_perfil, axis=1)

df['perfil_usuario'].value_counts()
```
El target perfil_usuario tiene 4 categor铆as que reflejan diferentes comportamientos comunicativos en la red:

- Influyente Activo: usuarios con alto alcance y actividad alta.
- Influyente Pasivo: usuarios con alcance alto pero poca interacci贸n.
- Usuario Participativo: personas comunes con mucha actividad.
- Usuario Pasivo: cuentas regulares con baja actividad.

# Selecci贸n de features relevantes
```{python}
features = [
    'content_clean',          # texto procesado
    'authorVerified',
    'authorFollowers',
    'hashtags_count',
    'mentions_count',
    'content_length',
    'account_age_days'
]

target = 'perfil_usuario'

X = df[features]
X["authorVerified"] = X["authorVerified"].astype(int)
y = df[target]

```

# PREPROCESAMIENTO DEL TEXTO (TF-IDF)

```{python}
text_features = ["content_clean"]
numeric_features = ["authorFollowers", "hashtags_count", "mentions_count", "content_length", "account_age_days"]
categorical_features = ["authorVerified"]

spanish_stopwords = stopwords.words('spanish')
text_transformer = TfidfVectorizer(stop_words=spanish_stopwords)
numeric_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown="ignore")
```
Dividi los features relevantes del dataset en 3 tipos de variables: textuales, numericas y categoricas.

Genere los 3 tipos de transformes para poder convertir los valores del dataset a datos que el modelo pueda entender.

# PREPROCESAMIENTO Y MODELADO

```{python}
preprocessor = ColumnTransformer(
    transformers=[
        ("text", text_transformer, "content_clean"),
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)
    ]
)

# Modelo base (simple y eficiente)

```
# Pipeline
```{python}
model = LogisticRegression(max_iter=300, multi_class="multinomial")

pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", model)
])
```
Use LogisticRegression que permite combinar de manera eficiente texto vectorizado, variables num茅ricas y categ贸ricas dentro de un mismo pipeline

Aplique TF-IDF obtener una matriz numerica que permita facilitar el analisis de los valores para mi modelo 

Use OneHotEncoder para convertir las variables categ贸rica en columnas binarias

Use StandardScaler para normalizar las diferentes escalas y que todas tengan el mismo peso en el modelo.

# Dividir los datos
```{python}
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)


```
# Fit

```{python}
pipeline.fit(X_train, y_train)

```
# Predict

```{python}
y_pred = pipeline.predict(X_test)
```
# EVALUACIN DEL MODELO
```{python}
print(" Reporte de Clasificaci贸n:\n")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred, labels=pipeline.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline.classes_)
disp.plot(cmap="Blues", xticks_rotation=45)
plt.title("Matriz de Confusi贸n - Clasificaci贸n de Perfiles de Usuario")
plt.show()
```

```{python}
# Comparar distribuciones reales y predichas
fig, ax = plt.subplots(1, 2, figsize=(12,5))

sns.countplot(y_test, ax=ax[0], palette="pastel")
ax[0].set_title("Distribuci贸n Real de Clases")
ax[0].set_xlabel("Perfil de Usuario")
ax[0].set_ylabel("Cantidad")

sns.countplot(y_pred, ax=ax[1], palette="pastel")
ax[1].set_title("Distribuci贸n Predicha por el Modelo")
ax[1].set_xlabel("Perfil de Usuario")
ax[1].set_ylabel("Cantidad")

plt.tight_layout()
plt.show()
```
