---
title: "MidTerm"
author: "Santiago Roman"
date: "10-04-2025"
format: 
  html:
    embed-resources: true 
---
# MIDTERM
## Problema de Regresión
### Import libraries 

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

```
### Cargar Data


```{python}
housing = fetch_california_housing()
X, y = housing.data, housing.target

print("Shape X:", X.shape, "Shape y:", y.shape)
```
### Split Data

```{python}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```
### Crear Pipeline


```{python}
reg_pipe = Pipeline([
    ("scaler", StandardScaler()), 
    ("regressor", LinearRegression())
])
```
### Entrenar modelo

```{python}
reg_pipe.fit(X_train, y_train)
```
### Predecir

```{python}
y_prep_pipe = reg_pipe.predict(X_test)
```
### Resultados
```{python}
train_sizes, train_scores, test_scores = learning_curve(
    reg_pipe, X, y, cv=5, scoring="r2", n_jobs=1
)

train_mean = np.mean(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)

plt.plot(train_sizes, train_mean, label="Entrenamiento")
plt.plot(train_sizes, test_mean, label="Validación")
plt.xlabel("Tamaño del conjunto de entrenamiento")
plt.ylabel("R² Score")
plt.title("Curva de Aprendizaje")
plt.legend()
plt.show()
```
La curva de aprendizaje se realizo tomando en cuenta el valor R2 el cual representa el porcentaje del comportamiento de los datos que el modelo logra entender. mostrando que el modelo aprende los patrones para poder hacer predicciones.
```{python}
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_prep_pipe, color='blue', alpha=0.7, s=10)
plt.title('Cargos reales vs. Cargos predichos')
plt.xlabel('Valores reales')
plt.ylabel('Valores predichos')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Línea de referencia
plt.legend(['Valores predichos', 'Línea de referencia'])
plt.show()
```
Esta grafica muestra la distribución de los datos al hacer la regresión lineal, donde se muestra los valores predichos y valores reales, además de una linea de referencia que muestra cuando los datos son predichos correctamente. En este caso los puntos se agrupan cerca de la linea de referencia aunque con cierta dispersión, lo cual muestra que el modelo acierta de forma general en gran parte de los datos, pero tiene errores en valores extremos.
```{python}
mae = mean_absolute_error(y_test, y_prep_pipe)
print(f"Error medio absoluto (MAE): {mae:.3f}")
```
### Prediccion
Se usa un nuevo registro para mostrar como funciona la prediccion.
```{python}
nuevo_registro = pd.DataFrame([[
    8.3252,   # MedInc - ingreso medio
    41.0,     # HouseAge - edad promedio de las casas
    6.9841,   # AveRooms - promedio de habitaciones
    1.0238,   # AveBedrms - promedio de dormitorios
    322.0,    # Population - población
    2.5556,   # AveOccup - ocupación promedio
    37.88,    # Latitude
    -122.23   # Longitude
]], columns=housing.feature_names)

prediccion = reg_pipe.predict(nuevo_registro)
print(f'Predicción del valor medio de la vivienda: ${prediccion[0]* 100000:.2f}')
```
## Problema de Clasificación
### Import libraries

```{python}
from sklearn.datasets import load_breast_cancer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, RocCurveDisplay,ConfusionMatrixDisplay

import seaborn as sns
import pandas as pd
```
### Load Data

```{python}
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv"

# Según el dataset, las columnas serían:
col_names = ["Pregnancies", "Glucose", "BloodPressure", "SkinThickness", 
            "Insulin", "BMI", "DiabetesPedigreeFunction", "Age", "Outcome"]
df = pd.read_csv(url, header=None, names=col_names)

cols_with_zeros = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
df[cols_with_zeros] = df[cols_with_zeros].replace(0, np.nan)
df = df.dropna()

X = df.drop("Outcome", axis=1).values
y = df["Outcome"].values
```
### Split Data

```{python}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```
### Crear Pipeline

```{python}
clf_pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("classifier", LogisticRegression(max_iter=500))
])
```
### Entrenar modelo

```{python}
clf_pipe.fit(X_train, y_train)
```
### Predecir

```{python}
y_prep_pipe = clf_pipe.predict(X_test)
```
### Evaluación

```{python}
print("Accuracy:", accuracy_score(y_test, y_prep_pipe))
print("Precision:", precision_score(y_test, y_prep_pipe))
print("Recall:", recall_score(y_test, y_prep_pipe))
print("F1 Score:", f1_score(y_test, y_prep_pipe))
```
### Matriz de confusión

```{python}
ConfusionMatrixDisplay.from_predictions(y_test,y_prep_pipe)
```
Esta matriz de confusion muestra la cantidad de datos que se llegan a predecir, asi se muestra que en realidad el modelo muestra lo siguiente:

- 45 casos fueron correctamente clasificados como No Diabetes 
- 16 casos fueron correctamente identificados como Diabetes
- 11 casos presentaron Falsos Negativos
- 8 casos presentaron Falsos Positivos 

### Curva ROC
```{python}
RocCurveDisplay.from_estimator(clf_pipe, X_test, y_test)
plt.show()
```
La Curva ROC evalúa el rendimiento del modelo de clasificación mostrando la relación entre la Tasa de Verdaderos Positivos y la Tasa de Falsos Positivos en diferentes umbrales de decisión. El modelo obtiene un AUC  de 0.83, lo que indica un 83% de probabilidad de clasificar correctamente un caso positivo por encima de uno negativo, siendo considerado un rendimiento bueno.